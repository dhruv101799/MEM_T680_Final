{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Import required libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a tool I have provided you to help you download your file.\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"\n",
    "    A function that downloads the data file from a URL\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        url where the file to download is located\n",
    "    filename : string\n",
    "        location where to save the file\n",
    "    reporthook : function\n",
    "        callback to display the download progress\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        urllib.request.urlretrieve(url, filename, reporthook)\n",
    "        \n",
    "def reporthook(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    A function that displays the status and speed of the download\n",
    "    \"\"\"\n",
    "\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration + 0.0001))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download your file by typing your first name into the name block\n",
    "# The name used is the first part of your first name as listed in BB learn\n",
    "# If you have problems downloading the data please reach out to me\n",
    "\n",
    "name = 'Dhruv'\n",
    "# download_file(f'https://zenodo.org/record/7339649/files/data_{name}.npz?download=1','data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_feat: (100000, 30)\n",
      "training_true: (100000, 3)\n",
      "validation_feat: (65536, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "data = np.load('data.npz')\n",
    "data_list = data.files\n",
    "for item in data_list:\n",
    "    print(f\"{item}: {data[item].shape}\")\n",
    "\n",
    "# print(data[\"training_true\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors from numpy arrays\n",
    "training_feat_np = data[data_list[0]]\n",
    "training_feat = torch.from_numpy(training_feat_np)\n",
    "\n",
    "training_true_np = data[data_list[1]]\n",
    "training_true = torch.from_numpy(training_true_np)\n",
    "\n",
    "validation_feat_np = data[data_list[2]]\n",
    "validation_feat = torch.from_numpy(validation_feat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  '''Dataset Class to store the samples and their corresponding labels, \n",
    "  and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray, device = 'cpu') -> None:\n",
    "\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "    self.X = torch.from_numpy(X.astype(np.float32)).to(device)\n",
    "    self.y = torch.from_numpy(y.astype(np.float32)).to(device)\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x0000027EB2522430>\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into test/train\n",
    "split_dataset = random_split(training_feat_np, \n",
    "                             lengths=[2/3, 1/3], \n",
    "                             generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Configure dataset\n",
    "training_data = Data(X=training_feat_np, y=training_true_np)\n",
    "testing_data = Data(X=validation_feat_np, y=training_true_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 30])\n",
      "Shape of y: torch.Size([64, 3]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "# test_dataloader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "  ''' Regression Model\n",
    "  ''' \n",
    "\n",
    "  # note, you can ignore the `:int` and `-> None` this is just more advanced doctring syntax\n",
    "  def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "      '''The network has 4 layers\n",
    "            - input layer\n",
    "            - ReLu\n",
    "            - hidden layer\n",
    "            - ReLu\n",
    "            - hidden layer\n",
    "            - ReLu\n",
    "            - output layer\n",
    "      '''\n",
    "      super(Neural_Network, self).__init__()\n",
    "      # in this part you should intantiate each of the layer components\n",
    "      # Type your code here\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "      # In this part you should build a model that returns the 3 outputs of the regression\n",
    "      # Type your code here\n",
    "      \n",
    "      return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ML_T680')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80c4cda4b32ad6e16c64aa1fd6e254f2a6a75936c807cf5e21680d140147b0d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
