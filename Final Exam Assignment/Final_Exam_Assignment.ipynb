{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Import required libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a tool I have provided you to help you download your file.\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"\n",
    "    A function that downloads the data file from a URL\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        url where the file to download is located\n",
    "    filename : string\n",
    "        location where to save the file\n",
    "    reporthook : function\n",
    "        callback to display the download progress\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        urllib.request.urlretrieve(url, filename, reporthook)\n",
    "        \n",
    "def reporthook(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    A function that displays the status and speed of the download\n",
    "    \"\"\"\n",
    "\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = int(progress_size / (1024 * duration + 0.0001))\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
    "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...100%, 24 MB, 373 KB/s, 66 seconds passeded"
     ]
    }
   ],
   "source": [
    "# You can download your file by typing your first name into the name block\n",
    "# The name used is the first part of your first name as listed in BB learn\n",
    "# If you have problems downloading the data please reach out to me\n",
    "\n",
    "name = 'Dhruv'\n",
    "# download_file(f'https://zenodo.org/record/7339649/files/data_{name}.npz?download=1','data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  '''Dataset Class to store the samples and their corresponding labels, \n",
    "  and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray, device = 'cuda') -> None:\n",
    "\n",
    "    # need to convert float64 to float32 else \n",
    "    # will get the following error\n",
    "    # RuntimeError: expected scalar type Double but found Float\n",
    "    self.X = torch.from_numpy(X.astype(np.float32)).to(device)\n",
    "    self.y = torch.from_numpy(y.astype(np.float32)).to(device)\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index: int) -> tuple:\n",
    "    return self.X[index], self.y[index]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_feat: (100000, 30)\n",
      "training_true: (100000, 3)\n",
      "validation_feat: (65536, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "data = np.load('data.npz')\n",
    "data_list = data.files\n",
    "for item in data_list:\n",
    "    print(f\"{item}: {data[item].shape}\")\n",
    "\n",
    "# print(data[\"training_true\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000234CFB76CD0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m valid_dataloader \u001b[39m=\u001b[39m DataLoader(data[\u001b[39m'\u001b[39m\u001b[39mvalidation_feat\u001b[39m\u001b[39m'\u001b[39m], batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(train_dataloader)\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m valid_dataloader:\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of X [N, C, H, W]: \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of y: \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(data['training_feat'], batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(data['validation_feat'], batch_size=batch_size)\n",
    "\n",
    "for X, y in valid_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ML_T680')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80c4cda4b32ad6e16c64aa1fd6e254f2a6a75936c807cf5e21680d140147b0d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
